{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "from llama_index.core.extractors import SummaryExtractor, QuestionsAnsweredExtractor, TitleExtractor\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.schema import MetadataMode\n",
    "\n",
    "text_splitter = TokenTextSplitter(separator=\" \", chunk_size=1024, chunk_overlap=128)\n",
    "title_extractor = TitleExtractor(llm=phi3, nodes=5, metadata_mode=MetadataMode.EMBED, num_workers=8)\n",
    "summary_extractor = SummaryExtractor(llm=phi3, metadata_mode=MetadataMode.EMBED, num_workers=8)\n",
    "qa_extractor = QuestionsAnsweredExtractor(llm=phi3, questions=3, num_workers=8)\n",
    "\n",
    "pipe = IngestionPipeline(transformations=[text_splitter, title_extractor, summary_extractor, qa_extractor])\n",
    "\n",
    "nodes = await pipe.arun(documents=documents, \n",
    "                 in_place=True,\n",
    "                 show_progress=True)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
